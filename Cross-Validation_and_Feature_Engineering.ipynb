{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the following two cells before you begin.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(10000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 10 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First, import the cleaned data set. Then, select the features from the DataFrame of the case study data.**\n",
    "    \n",
    "These features should be: `'LIMIT_BAL'`, `'EDUCATION'`, `'MARRIAGE'`, `'AGE'`, `'PAY_1'`, `'BILL_AMT1'`, `'BILL_AMT2'`, `'BILL_AMT3'`, `'BILL_AMT4'`, `'BILL_AMT5'`, `'BILL_AMT6'`, `'PAY_AMT1'`, `'PAY_AMT2'`, `'PAY_AMT3'`, `'PAY_AMT4'`, `'PAY_AMT5'`, AND `'PAY_AMT6'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data set\n",
    "import numpy as np #numerical computation\n",
    "import pandas as pd #data wrangling\n",
    "import matplotlib.pyplot as plt #plotting package\n",
    "#Next line helps with rendering plots\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl #add'l plotting functionality\n",
    "mpl.rcParams['figure.dpi'] = 400 #high res figures\n",
    "df = pd.read_csv(r'C:\\Users\\sujith\\Desktop\\Technocolabs\\problem2\\Project-Data-Set-Repository-master\\Project-Data-Set-Repository-master\\Data set\\cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features list\n",
    "X = df[['LIMIT_BAL', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_1', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5','PAY_AMT6']]\n",
    "y = df[['default payment next month']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_1</th>\n",
       "      <th>BILL_AMT1</th>\n",
       "      <th>BILL_AMT2</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>3913</td>\n",
       "      <td>3102</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2682</td>\n",
       "      <td>1725</td>\n",
       "      <td>2682</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>29239</td>\n",
       "      <td>14027</td>\n",
       "      <td>13559</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>46990</td>\n",
       "      <td>48233</td>\n",
       "      <td>49291</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>8617</td>\n",
       "      <td>5670</td>\n",
       "      <td>35835</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26659</td>\n",
       "      <td>220000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>188948</td>\n",
       "      <td>192815</td>\n",
       "      <td>208365</td>\n",
       "      <td>88004</td>\n",
       "      <td>31237</td>\n",
       "      <td>15980</td>\n",
       "      <td>8500</td>\n",
       "      <td>20000</td>\n",
       "      <td>5003</td>\n",
       "      <td>3047</td>\n",
       "      <td>5000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26660</td>\n",
       "      <td>150000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>-1</td>\n",
       "      <td>1683</td>\n",
       "      <td>1828</td>\n",
       "      <td>3502</td>\n",
       "      <td>8979</td>\n",
       "      <td>5190</td>\n",
       "      <td>0</td>\n",
       "      <td>1837</td>\n",
       "      <td>3526</td>\n",
       "      <td>8998</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26661</td>\n",
       "      <td>30000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>3565</td>\n",
       "      <td>3356</td>\n",
       "      <td>2758</td>\n",
       "      <td>20878</td>\n",
       "      <td>20582</td>\n",
       "      <td>19357</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22000</td>\n",
       "      <td>4200</td>\n",
       "      <td>2000</td>\n",
       "      <td>3100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26662</td>\n",
       "      <td>80000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>-1645</td>\n",
       "      <td>78379</td>\n",
       "      <td>76304</td>\n",
       "      <td>52774</td>\n",
       "      <td>11855</td>\n",
       "      <td>48944</td>\n",
       "      <td>85900</td>\n",
       "      <td>3409</td>\n",
       "      <td>1178</td>\n",
       "      <td>1926</td>\n",
       "      <td>52964</td>\n",
       "      <td>1804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26663</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>47929</td>\n",
       "      <td>48905</td>\n",
       "      <td>49764</td>\n",
       "      <td>36535</td>\n",
       "      <td>32428</td>\n",
       "      <td>15313</td>\n",
       "      <td>2078</td>\n",
       "      <td>1800</td>\n",
       "      <td>1430</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26664 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LIMIT_BAL  EDUCATION  MARRIAGE  AGE  PAY_1  BILL_AMT1  BILL_AMT2  \\\n",
       "0          20000          2         1   24      2       3913       3102   \n",
       "1         120000          2         2   26     -1       2682       1725   \n",
       "2          90000          2         2   34      0      29239      14027   \n",
       "3          50000          2         1   37      0      46990      48233   \n",
       "4          50000          2         1   57     -1       8617       5670   \n",
       "...          ...        ...       ...  ...    ...        ...        ...   \n",
       "26659     220000          3         1   39      0     188948     192815   \n",
       "26660     150000          3         2   43     -1       1683       1828   \n",
       "26661      30000          2         2   37      4       3565       3356   \n",
       "26662      80000          3         1   41      1      -1645      78379   \n",
       "26663      50000          2         1   46      0      47929      48905   \n",
       "\n",
       "       BILL_AMT3  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  \\\n",
       "0            689          0          0          0         0       689   \n",
       "1           2682       3272       3455       3261         0      1000   \n",
       "2          13559      14331      14948      15549      1518      1500   \n",
       "3          49291      28314      28959      29547      2000      2019   \n",
       "4          35835      20940      19146      19131      2000     36681   \n",
       "...          ...        ...        ...        ...       ...       ...   \n",
       "26659     208365      88004      31237      15980      8500     20000   \n",
       "26660       3502       8979       5190          0      1837      3526   \n",
       "26661       2758      20878      20582      19357         0         0   \n",
       "26662      76304      52774      11855      48944     85900      3409   \n",
       "26663      49764      36535      32428      15313      2078      1800   \n",
       "\n",
       "       PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \n",
       "0             0         0         0         0  \n",
       "1          1000      1000         0      2000  \n",
       "2          1000      1000      1000      5000  \n",
       "3          1200      1100      1069      1000  \n",
       "4         10000      9000       689       679  \n",
       "...         ...       ...       ...       ...  \n",
       "26659      5003      3047      5000      1000  \n",
       "26660      8998       129         0         0  \n",
       "26661     22000      4200      2000      3100  \n",
       "26662      1178      1926     52964      1804  \n",
       "26663      1430      1000      1000      1000  \n",
       "\n",
       "[26664 rows x 17 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default payment next month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26659</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26660</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26661</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26662</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26663</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26664 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       default payment next month\n",
       "0                               1\n",
       "1                               1\n",
       "2                               0\n",
       "3                               0\n",
       "4                               0\n",
       "...                           ...\n",
       "26659                           0\n",
       "26660                           0\n",
       "26661                           1\n",
       "26662                           1\n",
       "26663                           1\n",
       "\n",
       "[26664 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________\n",
    "**Next, make a 80:20 train/test split using a random seed of 24.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________\n",
    "**Then, instantiate the `MinMaxScaler` to scale the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________\n",
    "**Next, instantiate a logistic regression model with the `saga` solver, L1 penalty, and set `max_iter` to 1,000 as we want the solver to have enough iterations to find a good solution.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=1000, multi_class='warn',\n",
    "          n_jobs=None, penalty='l1', random_state=None, solver='saga',\n",
    "          tol=0.0001, verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________\n",
    "**Next, import the `Pipeline` class and create a `Pipeline` with the scaler and the logistic regression model, using the names `'scaler'` and `'model'` for the steps, respectively.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('model', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=1000, multi_class='warn',\n",
    "          n_jobs=None, penalty='l1', random_state=None, solver='saga',\n",
    "          tol=0.0001, verbose=0, warm_start=False))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('model',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=1000,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l1', random_state=None,\n",
       "                                    solver='saga', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________\n",
    "**Now, use the `get_params` method to view the parameters from each stage of the pipeline.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('scaler',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "  ('model',\n",
       "   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                      intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                      multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                      random_state=None, solver='saga', tol=0.0001, verbose=0,\n",
       "                      warm_start=False))],\n",
       " 'verbose': False,\n",
       " 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'model': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                    intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                    multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                    random_state=None, solver='saga', tol=0.0001, verbose=0,\n",
       "                    warm_start=False),\n",
       " 'scaler__copy': True,\n",
       " 'scaler__with_mean': True,\n",
       " 'scaler__with_std': True,\n",
       " 'model__C': 1.0,\n",
       " 'model__class_weight': None,\n",
       " 'model__dual': False,\n",
       " 'model__fit_intercept': True,\n",
       " 'model__intercept_scaling': 1,\n",
       " 'model__l1_ratio': None,\n",
       " 'model__max_iter': 1000,\n",
       " 'model__multi_class': 'warn',\n",
       " 'model__n_jobs': None,\n",
       " 'model__penalty': 'l1',\n",
       " 'model__random_state': None,\n",
       " 'model__solver': 'saga',\n",
       " 'model__tol': 0.0001,\n",
       " 'model__verbose': 0,\n",
       " 'model__warm_start': False}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use `get_params`\n",
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use the `set_params` method to change the the `model__C` parameter to 2.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('scaler',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "  ('model',\n",
       "   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                      intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                      multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                      random_state=None, solver='saga', tol=0.0001, verbose=0,\n",
       "                      warm_start=False))],\n",
       " 'verbose': False,\n",
       " 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'model': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                    intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                    multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                    random_state=None, solver='saga', tol=0.0001, verbose=0,\n",
       "                    warm_start=False),\n",
       " 'scaler__copy': True,\n",
       " 'scaler__with_mean': True,\n",
       " 'scaler__with_std': True,\n",
       " 'model__C': 1.0,\n",
       " 'model__class_weight': None,\n",
       " 'model__dual': False,\n",
       " 'model__fit_intercept': True,\n",
       " 'model__intercept_scaling': 1,\n",
       " 'model__l1_ratio': None,\n",
       " 'model__max_iter': 1000,\n",
       " 'model__multi_class': 'warn',\n",
       " 'model__n_jobs': None,\n",
       " 'model__penalty': 'l1',\n",
       " 'model__random_state': None,\n",
       " 'model__solver': 'saga',\n",
       " 'model__tol': 0.0001,\n",
       " 'model__verbose': 0,\n",
       " 'model__warm_start': False}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View what `model__C` is set to currently\n",
    "pipe.get_params(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('model',\n",
       "                 LogisticRegression(C=2.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=1000,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l1', random_state=None,\n",
       "                                    solver='saga', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change `model__C` to 2\n",
    "\n",
    "pipe.set_params(model__C = 2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________\n",
    "**Then, create a smaller range of C values to test with cross-validation, as these models will take longer to train and test with more data than our previous activities.**\n",
    "\n",
    "**Use C_vals = [$10^2$, $10$, $1$, $10^{-1}$, $10^{-2}$, $10^{-3}$].**\n",
    "\n",
    "\n",
    "<details>\n",
    "    <summary>Hint:</summary>\n",
    "    Recall that exponents in Python use the ** operator.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('scaler',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "  ('model',\n",
       "   LogisticRegression(C=[100, 10, 1, 0.1, 0.01, 0.001], class_weight=None,\n",
       "                      dual=False, fit_intercept=True, intercept_scaling=1,\n",
       "                      l1_ratio=None, max_iter=1000, multi_class='warn',\n",
       "                      n_jobs=None, penalty='l1', random_state=None, solver='saga',\n",
       "                      tol=0.0001, verbose=0, warm_start=False))],\n",
       " 'verbose': False,\n",
       " 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'model': LogisticRegression(C=[100, 10, 1, 0.1, 0.01, 0.001], class_weight=None,\n",
       "                    dual=False, fit_intercept=True, intercept_scaling=1,\n",
       "                    l1_ratio=None, max_iter=1000, multi_class='warn',\n",
       "                    n_jobs=None, penalty='l1', random_state=None, solver='saga',\n",
       "                    tol=0.0001, verbose=0, warm_start=False),\n",
       " 'scaler__copy': True,\n",
       " 'scaler__with_mean': True,\n",
       " 'scaler__with_std': True,\n",
       " 'model__C': [100, 10, 1, 0.1, 0.01, 0.001],\n",
       " 'model__class_weight': None,\n",
       " 'model__dual': False,\n",
       " 'model__fit_intercept': True,\n",
       " 'model__intercept_scaling': 1,\n",
       " 'model__l1_ratio': None,\n",
       " 'model__max_iter': 1000,\n",
       " 'model__multi_class': 'warn',\n",
       " 'model__n_jobs': None,\n",
       " 'model__penalty': 'l1',\n",
       " 'model__random_state': None,\n",
       " 'model__solver': 'saga',\n",
       " 'model__tol': 0.0001,\n",
       " 'model__verbose': 0,\n",
       " 'model__warm_start': False}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_vals = [ 100 ,  10 ,  1 ,  0.1 ,  0.01 ,  0.001 ]\n",
    "pipe.set_params(model__C = C_vals)\n",
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, define `k_folds` using `StratifiedKFold`. The number of folds should be 4. Set the random state to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StratifiedKFold(n_splits=4, random_state=1, shuffle=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "cv = StratifiedKFold(n_splits=4,random_state=1)\n",
    "classifier = LogisticRegression(random_state=1)\n",
    "cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________\n",
    "**Next, make a new version of the `cross_val_C_search` function, called `cross_val_C_search_pipe`. Instead of the model argument, this function will take a pipeline argument. The changes inside the function will be to set the `C` value using `set_params(model__C = <value you want to test>)` on the pipeline, replacing the model with the pipeline for the fit and `predict_proba` methods, and accessing the `C` value using `pipeline.get_params()['model__C']` for the printed status update.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_C_search_pipe(pipe1):\n",
    "    pipe1.set_params(model__C = 2)\n",
    "    print(pipe1.get_params()['model__C'])\n",
    "    \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "pipe1 = Pipeline([('scaler', StandardScaler()), ('model', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=1000, multi_class='warn',\n",
    "          n_jobs=None, penalty='l1', random_state=None, solver='saga',\n",
    "          tol=0.0001, verbose=0, warm_start=False))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________\n",
    "**Now, run this function as in the previous activity, but using the new range of `C` values, the pipeline you created, and the features and response variable from the training split of the case study data.**\n",
    "\n",
    "    You may see warnings here, or in later steps, about the non-convergence of the solver; you could experiment with the `tol` or `max_iter`` options to try and achieve convergence, although the results you obtain with `max_iter = 1000` are likely to be sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "ret = cross_val_C_search_pipe(pipe1)\n",
    "ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________\n",
    "**Plot the average training and testing ROC AUC across folds, for each `np.log(C_vals)` value.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda\\New folder\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "F:\\anaconda\\New folder\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected array-like (array or non-string sequence), got LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n                   multi_class='warn', n_jobs=None, penalty='l2',\n                   random_state=1, solver='warn', tol=0.0001, verbose=0,\n                   warm_start=False)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-980e41dbecbe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     viz = roc_curve(classifier, X_test, y_test,\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                 )\n",
      "\u001b[1;32mF:\\anaconda\\New folder\\lib\\site-packages\\sklearn\\metrics\\ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[0;32m    620\u001b[0m     \"\"\"\n\u001b[0;32m    621\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[1;32m--> 622\u001b[1;33m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    623\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m     \u001b[1;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\New folder\\lib\\site-packages\\sklearn\\metrics\\ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    391\u001b[0m     \"\"\"\n\u001b[0;32m    392\u001b[0m     \u001b[1;31m# Check to make sure y_true is valid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 393\u001b[1;33m     \u001b[0my_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    394\u001b[0m     if not (y_type == \"binary\" or\n\u001b[0;32m    395\u001b[0m             (y_type == \"multiclass\" and pos_label is not None)):\n",
      "\u001b[1;32mF:\\anaconda\\New folder\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    239\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mvalid\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m         raise ValueError('Expected array-like (array or non-string sequence), '\n\u001b[1;32m--> 241\u001b[1;33m                          'got %r' % y)\n\u001b[0m\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[0msparseseries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'SparseSeries'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected array-like (array or non-string sequence), got LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n                   multi_class='warn', n_jobs=None, penalty='l2',\n                   random_state=1, solver='warn', tol=0.0001, verbose=0,\n                   warm_start=False)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2400x1600 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fig, ax = plt.subplots()\n",
    "for i, (train, test) in enumerate(cv.split(X, y)):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    viz = roc_curve(classifier, X_test, y_test,\n",
    "                         \n",
    "                         alpha=0.3, lw=1, ax=ax)\n",
    "    interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(viz.roc_auc)\n",
    "\n",
    "ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "        label='Chance', alpha=.8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________\n",
    "**Up next, create interaction features for the case study data using scikit-learn's `PolynomialFeatures`. You should use 2 as the degree of polynomial features. Confirm that the number of new features makes sense.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolynomialFeatures(degree=2, include_bias=True, interaction_only=False,\n",
       "                   order='C')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "pf = PolynomialFeatures(degree=2,  interaction_only=False, include_bias=True, order='C')\n",
    "pf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________\n",
    "**Finally, repeat the cross-validation procedure and observe the model performance now.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the new features, make a 80:20 train/test split using a random seed of 24.**\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda\\New folder\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "F:\\anaconda\\New folder\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                   random_state=None, solver='saga', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the cross_val_C_search_pipe() function using the new training data.\n",
    "# All other parameters should remain the same.\n",
    "# Note that this training may take a few minutes due to the larger number of features.\n",
    "cross_val_C_search_pipe(pipe1)\n",
    "model = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=1000, multi_class='warn',\n",
    "          n_jobs=None, penalty='l1', random_state=None, solver='saga',\n",
    "          tol=0.0001, verbose=0, warm_start=False)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "eid": "b4f5a"
   },
   "outputs": [],
   "source": [
    "# Plot the average training and testing ROC AUC across folds, for each C value.\n",
    "fig, ax = plt.subplots()\n",
    "viz = roc_curve(classifier, X_test, y_test)\n",
    "viz.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "        label='Chance', alpha=.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Take a look at the above graph. Does the average cross-validation testing performance improve with the interaction features? Is regularization useful?**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
